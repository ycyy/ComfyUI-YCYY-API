{
    "YCYY_Gemini_Image_API": {
        "display_name": "Gemini Image API",
        "inputs": {
            "images": {
                "name": "image",
                "tooltip": "Optional image(s) to use as context for the model"
            },
            "prompt": {
                "name": "prompt"
            },
            "model": {
                "name": "model"
            },
            "aspectRatio": {
                "name": "aspectRatio",
                "tooltip": "The model defaults to matching the output image size to that of your input image, or otherwise generates 1:1 squares. You can control the aspect ratio of the output image using the aspect ratio"
            },
            "seed": {
                "name": "seed",
                "tooltip": "Seed to use for generation"
            }
        },
        "outputs": {
            "0": {
                "name": "Image"
            },
            "1": {
                "name": "String"
            }
        }
    },
    "YCYY_Gemini_Image_Preset":{
        "display_name": "Gemini Image Preset",
        "description": "This node provides presets for the Gemini Image API.",
        "inputs": {
            "preset":{
                "name": "preset",
                "tooltip": "Gemini image preset name"
            },
            "description":{
                "name": "description",
                "tooltip": "Gemini image preset description"
            },
            "prompt":{
                "name": "prompt",
                "tooltip": "Gemini image preset prompt"
            }
        },
        "outputs": {
            "0": {
                "name": "String"
            }
        }
    },
    "YCYY_Ollama_VLM_API":{
        "display_name": "Ollama VLM API",
        "description": "This node uses the Ollama VLM model for image reasoning and analysis.",
        "inputs": {
            "image":{
                "name": "image",
                "tooltip": "Image used for analysis"
            },
            "model": {
                "name": "model"
            }
        },
        "outputs": {
            "0": {
                "name": "String"
            }
        }
    },
    "YCYY_Ollama_LLM_API":{
        "display_name": "Ollama LLM API",
        "description": "This node uses the Ollama LLM model for conversation.",
        "inputs": {
            "system_prompt":{
                "name": "system_prompt"
            },
            "user_prompt":{
                "name": "user_prompt"
            },
            "model": {
                "name": "model"
            },
            "persist_context": {
                "name": "persist_context",
                "tooltip": "Persist chat context between calls (multi-turn conversation)"
            }
        },
        "outputs": {
            "0": {
                "name": "Result",
                "tooltip": "Return result"
            },
            "1": {
                "name": "Conversation",
                "tooltip": "All historical conversation"
            }
        }
    }
}